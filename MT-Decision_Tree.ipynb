{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rd\n",
    "import time\n",
    "import pickle\n",
    "from collections import defaultdict \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Nos modules\n",
    "import randomforest as rf\n",
    "import params_tuning as pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importation des données"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1000, 32)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        filename  chroma_stft       rms  spectral_centroid  \\\n0  country.00094     0.366838  0.206715        1474.849928   \n1  country.00025     0.347253  0.079920        1565.431223   \n2  country.00076     0.297332  0.128385        1321.679067   \n3  country.00030     0.221390  0.079631        1240.515214   \n4  country.00089     0.322114  0.104638        1321.678546   \n\n   spectral_bandwidth      rolloff  zero_crossing_rate      mfcc1      mfcc2  \\\n0         1745.839794  3108.264538            0.062993 -104.34503  136.39078   \n1         2016.069774  3188.930717            0.057303 -200.55273  119.67490   \n2         1409.586676  2590.392670            0.066525 -183.93301  159.80644   \n3         1996.754074  2412.635411            0.042844 -277.08127  128.25803   \n4         1667.211777  2583.926042            0.052503 -205.12328  140.99438   \n\n       mfcc3  ...     mfcc16    mfcc17    mfcc18    mfcc19     mfcc20  \\\n0 -20.945368  ...   2.197093 -7.109390  1.849674  1.675598  -1.492039   \n1  -3.610737  ... -11.293138 -8.870809 -8.073557 -3.161044   0.330751   \n2 -23.158834  ...  -3.583324 -9.062474 -3.159365 -4.068544  -7.052489   \n3  42.433240  ...   1.391878  3.080010  2.513260 -1.051766  -2.753359   \n4  -8.959963  ...   3.140506 -4.527332  2.654261 -3.122376 -10.710899   \n\n   spectral_contrast  spectral_flatness   tonnetz  estimated_tempo  \\\n0          23.567712           0.001825  0.026578       112.347147   \n1          19.845071           0.008667  0.018447       143.554688   \n2          23.526738           0.001220 -0.013900       143.554688   \n3          22.093318           0.002381 -0.009946       161.499023   \n4          24.189410           0.001850  0.002900       143.554688   \n\n   genre/label  \n0      country  \n1      country  \n2      country  \n3      country  \n4      country  \n\n[5 rows x 32 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>chroma_stft</th>\n      <th>rms</th>\n      <th>spectral_centroid</th>\n      <th>spectral_bandwidth</th>\n      <th>rolloff</th>\n      <th>zero_crossing_rate</th>\n      <th>mfcc1</th>\n      <th>mfcc2</th>\n      <th>mfcc3</th>\n      <th>...</th>\n      <th>mfcc16</th>\n      <th>mfcc17</th>\n      <th>mfcc18</th>\n      <th>mfcc19</th>\n      <th>mfcc20</th>\n      <th>spectral_contrast</th>\n      <th>spectral_flatness</th>\n      <th>tonnetz</th>\n      <th>estimated_tempo</th>\n      <th>genre/label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>country.00094</td>\n      <td>0.366838</td>\n      <td>0.206715</td>\n      <td>1474.849928</td>\n      <td>1745.839794</td>\n      <td>3108.264538</td>\n      <td>0.062993</td>\n      <td>-104.34503</td>\n      <td>136.39078</td>\n      <td>-20.945368</td>\n      <td>...</td>\n      <td>2.197093</td>\n      <td>-7.109390</td>\n      <td>1.849674</td>\n      <td>1.675598</td>\n      <td>-1.492039</td>\n      <td>23.567712</td>\n      <td>0.001825</td>\n      <td>0.026578</td>\n      <td>112.347147</td>\n      <td>country</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>country.00025</td>\n      <td>0.347253</td>\n      <td>0.079920</td>\n      <td>1565.431223</td>\n      <td>2016.069774</td>\n      <td>3188.930717</td>\n      <td>0.057303</td>\n      <td>-200.55273</td>\n      <td>119.67490</td>\n      <td>-3.610737</td>\n      <td>...</td>\n      <td>-11.293138</td>\n      <td>-8.870809</td>\n      <td>-8.073557</td>\n      <td>-3.161044</td>\n      <td>0.330751</td>\n      <td>19.845071</td>\n      <td>0.008667</td>\n      <td>0.018447</td>\n      <td>143.554688</td>\n      <td>country</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>country.00076</td>\n      <td>0.297332</td>\n      <td>0.128385</td>\n      <td>1321.679067</td>\n      <td>1409.586676</td>\n      <td>2590.392670</td>\n      <td>0.066525</td>\n      <td>-183.93301</td>\n      <td>159.80644</td>\n      <td>-23.158834</td>\n      <td>...</td>\n      <td>-3.583324</td>\n      <td>-9.062474</td>\n      <td>-3.159365</td>\n      <td>-4.068544</td>\n      <td>-7.052489</td>\n      <td>23.526738</td>\n      <td>0.001220</td>\n      <td>-0.013900</td>\n      <td>143.554688</td>\n      <td>country</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>country.00030</td>\n      <td>0.221390</td>\n      <td>0.079631</td>\n      <td>1240.515214</td>\n      <td>1996.754074</td>\n      <td>2412.635411</td>\n      <td>0.042844</td>\n      <td>-277.08127</td>\n      <td>128.25803</td>\n      <td>42.433240</td>\n      <td>...</td>\n      <td>1.391878</td>\n      <td>3.080010</td>\n      <td>2.513260</td>\n      <td>-1.051766</td>\n      <td>-2.753359</td>\n      <td>22.093318</td>\n      <td>0.002381</td>\n      <td>-0.009946</td>\n      <td>161.499023</td>\n      <td>country</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>country.00089</td>\n      <td>0.322114</td>\n      <td>0.104638</td>\n      <td>1321.678546</td>\n      <td>1667.211777</td>\n      <td>2583.926042</td>\n      <td>0.052503</td>\n      <td>-205.12328</td>\n      <td>140.99438</td>\n      <td>-8.959963</td>\n      <td>...</td>\n      <td>3.140506</td>\n      <td>-4.527332</td>\n      <td>2.654261</td>\n      <td>-3.122376</td>\n      <td>-10.710899</td>\n      <td>24.189410</td>\n      <td>0.001850</td>\n      <td>0.002900</td>\n      <td>143.554688</td>\n      <td>country</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 32 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On supprime la premiere colonne\n",
    "data = data.drop(['filename'],axis=1)\n",
    "\n",
    "# On change les noms des genres par des entiers (de 0 a 9) car notre random forest ne prend en compte que des entiers comme labels\n",
    "genre_list = data.iloc[:, -1]\n",
    "encoder = LabelEncoder()\n",
    "labels = encoder.fit_transform(genre_list)\n",
    "data.iloc[:, -1] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On normalise le dataset\n",
    "scaler = StandardScaler()\n",
    "data_normalized = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Apprentissage du modèle de base\n",
    "On reprend le modèle que nous avions implementé lors du précédent projet."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "data_train (800, 30) | label_train (800,)\ndata_test  (200, 30) | label_test  (200,)\n"
    }
   ],
   "source": [
    "# On separe le dataset en train set et test set (80%/20%)\n",
    "data_train, data_test, label_train, label_test = train_test_split(data_normalized, labels, test_size=0.2)\n",
    "n_samples, n_features = data_train.shape\n",
    "print(\"data_train {0} | label_train {1}\".format(data_train.shape, label_train.shape))\n",
    "print(\"data_test  {0} | label_test  {1}\".format(data_test.shape, label_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Execution time to build the decision tree: 5.266375 sec\n"
    }
   ],
   "source": [
    "# Initialisation de la random forest\n",
    "# par defaut n_cuts = 40, max_depth = 20, max_features = \"sqrt\"\n",
    "base_model = rf.OurDecisionTreeClassifier() \n",
    "\n",
    "# Entrainement du modèle de base\n",
    "start = time.time()\n",
    "base_model.fit(data_train, label_train)\n",
    "end = time.time()\n",
    "print(\"Execution time to build the decision tree: %f sec\"%(float(end) - float(start)))\n",
    "\n",
    "# Test de validation\n",
    "our_predictions = base_model.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison avec sklearn\n",
    "sklearn_rf = DecisionTreeClassifier(max_depth=20, max_features='sqrt')\n",
    "sklearn_rf.fit(data_train, label_train)\n",
    "sklearn_predictions = sklearn_rf.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Our decision tree score : 39.5 %\nSklearn score : 51.5 %\n"
    }
   ],
   "source": [
    "print(\"Our decision tree score : {} %\".format(base_model.score(our_predictions, label_test) * 100))  \n",
    "print(\"Sklearn score : {} %\".format(base_model.score(sklearn_predictions, label_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a une très grande marge d'amélioration."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature selection\n",
    "Un moyen d'améliorer notre modèle est de sélectionner les caractéristiques les plus discriminantes. \n",
    "\n",
    "* https://towardsdatascience.com/de-coding-random-forests-82d4dcbb91a1\n",
    "* https://hub.packtpub.com/4-ways-implement-feature-selection-python-machine-learning/"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Shape of the dataset  (800, 30)\nSize of the dataset before feature selection: 0.19 MB\n"
    }
   ],
   "source": [
    "print(\"Shape of the dataset \", data_train.shape)\n",
    "print(\"Size of the dataset before feature selection: %.2f MB\"%(data_train.nbytes/1e6))\n",
    "features_name = data.drop(['genre/label'], axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Execution time to find the most important feature: 0.675194 sec\n"
    }
   ],
   "source": [
    "start = time.time()\n",
    "features, importances = base_model.findFeatureImportance(data_train, label_train)\n",
    "end = time.time()\n",
    "print(\"Execution time to find the most important feature: %f sec\"%(float(end) - float(start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "               feature  importance\n5   zero_crossing_rate     0.33000\n1                  rms     0.30625\n3   spectral_bandwidth     0.30000\n21              mfcc16     0.21750\n7                mfcc2     0.20000\n10               mfcc5     0.09375\n0          chroma_stft     0.00000\n20              mfcc15     0.00000\n22              mfcc17     0.00000\n23              mfcc18     0.00000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature</th>\n      <th>importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>zero_crossing_rate</td>\n      <td>0.33000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>rms</td>\n      <td>0.30625</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>spectral_bandwidth</td>\n      <td>0.30000</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>mfcc16</td>\n      <td>0.21750</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>mfcc2</td>\n      <td>0.20000</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>mfcc5</td>\n      <td>0.09375</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>chroma_stft</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>mfcc15</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>mfcc17</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>mfcc18</td>\n      <td>0.00000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(zip(features_name, importances), columns = ['feature','importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "feature_importances[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Shape of the dataset  (800, 25)\nSize of the dataset after feature selection: 0.16 MB\n"
    }
   ],
   "source": [
    "# On selectionne les 25 meilleures\n",
    "indexes = feature_importances.index[:25]\n",
    "\n",
    "# On transforme le dataset d'entrainement (fs = feature selection)\n",
    "fs_data_train = rf.transform(data_train, indexes)\n",
    "fs_data_test = rf.transform(data_test, indexes)\n",
    "print(\"Shape of the dataset \", fs_data_train.shape)\n",
    "print(\"Size of the dataset after feature selection: %.2f MB\"%(fs_data_train.nbytes/1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Execution time for building the forest: 4.233705 sec\n"
    }
   ],
   "source": [
    "# Entrainement du modèle de base avec feature selection\n",
    "start = time.time()\n",
    "base_model.fit(fs_data_train, label_train)\n",
    "end = time.time()\n",
    "print(\"Execution time for building the forest: %f sec\"%(float(end) - float(start)))\n",
    "\n",
    "# Test de validation\n",
    "our_predictions = base_model.predict(fs_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison avec sklearn\n",
    "sklearn_rf.fit(fs_data_train, label_train)\n",
    "sklearn_predictions = sklearn_rf.predict(fs_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Our random forest score after feature selection: 41.0 %\nSklearn score : 58.5 %\n"
    }
   ],
   "source": [
    "# Score\n",
    "print(\"Our random forest score after feature selection: {} %\".format(base_model.score(our_predictions, label_test) * 100))\n",
    "print(\"Sklearn score : {} %\".format(base_model.score(sklearn_predictions, label_test)*100))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Réglage des hyperparamètres\n",
    "Nous nous sommes fortement inspiré de la méthode décrite dans cet article [W. Koehrsen. Hyperparameter Tuning the Random Forest in Python, Janv. 2018](https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre modèle a trois paramètres que nous souhaitons optimiser  :\n",
    "   - `n_cuts` -- le nombre de coupes à tester pour trouver la meilleure\n",
    "   - `max_depth` -- la profondeur maximale de chaque arbre\n",
    "   - `max_features` -- le nombre de caractéristiques à choisir lors de l'entraînement du modèle"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour avoir une première idée de la meilleure combinaison d'hyperparamètres, nous allons effectuer une ... (Random Search Cross Validation). Cela consiste à tester un large choix de combinaisons qui ont été formées en tirant aléatoirement des valeurs dans une grille d'hyperparamètres."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Random Search Cross Validation"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit la grille pour la recherche aléatoire (Random Hyperparameter Grid) :"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Grille d'hyperparametres :\n\n{'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n 'max_features': [10, 15, 20, 25, 30, 'sqrt'],\n 'n_cuts': [10, 20, 30, 40, 50]}\n"
    }
   ],
   "source": [
    "# n_cuts\n",
    "n_cuts = [int(x) for x in np.linspace(start = 10, stop = 50, num = 5)] \n",
    "\n",
    "# max_depth\n",
    "max_depth = [int(x) for x in np.linspace(10, 100, num = 10)]\n",
    "\n",
    "# max_features\n",
    "max_features = [int(x) for x in np.linspace(10, n_features, num = 5)]\n",
    "max_features.append(\"sqrt\")\n",
    "\n",
    "\n",
    "# Creation de la grille\n",
    "random_grid = {'n_cuts': n_cuts,\n",
    "                'max_depth': max_depth,\n",
    "                'max_features': max_features}\n",
    "\n",
    "from pprint import pprint\n",
    "print(\"Grille d'hyperparametres :\\n\")\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au lieu de tester 5 x 10 x 5 = 250 combinaisons d'hyperparamètres, nous allons seulement en sélectionner quelques unes aléatoirement."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On procède à la recherche randomisée sur 50 combinaisons, en utilisant une 5-fold CV"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Execution time for random search training: 208.507121 sec\n"
    }
   ],
   "source": [
    "# Definition de la recherche randomisee\n",
    "random_dtc = pt.RandomizedSearchCV(estimator = rf.OurDecisionTreeClassifier, \n",
    "                                  param_distributions = random_grid, \n",
    "                                  n_iter = 20, \n",
    "                                  cv = 5)\n",
    "\n",
    "# Entrainement du modele\n",
    "start = time.time()\n",
    "random_dtc.fit(data_train, label_train)\n",
    "end = time.time()\n",
    "print(\"Execution time for random search training: %f sec\"%(float(end) - float(start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les resultats"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "La meilleure combinaison d'hyperparametres avec la recherche randomisee est :\n {'n_cuts': 50, 'max_depth': 30, 'max_features': 20}\n\nLe score moyen du modele avec ces hyperparametres est :\n 49.75\n"
    }
   ],
   "source": [
    "print(\"La meilleure combinaison d'hyperparametres avec la recherche randomisee est :\\n\", random_dtc.best_params_)\n",
    "print(\"\")\n",
    "print(\"Le score moyen du modele avec ces hyperparametres est :\\n %.2f\"%random_dtc.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Grid Search Cross Validation\n",
    "On peut maintenant effectuer une recherche plus exhaustive centrée sur ces valeurs."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition de la grille d'hyperparamètres basée sur les résultats de la recherche randomisée\n",
    "n_cuts = [45,50,55]\n",
    "max_depth = [25,30,35]\n",
    "max_features = [15,20,25]\n",
    "\n",
    "param_grid = {\n",
    "    'n_cuts': n_cuts,\n",
    "    'max_depth': max_depth,\n",
    "    'max_features': max_features,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Execution time for random search training: 643.185591 sec\n"
    }
   ],
   "source": [
    "# 7-8 MIN\n",
    "# Instanciation du grid search model\n",
    "grid_search_dtc = pt.GridSearchCV(estimator = rf.OurDecisionTreeClassifier, \n",
    "                                  param_distributions = param_grid,\n",
    "                                  cv = 5)\n",
    "\n",
    "# Entrainement du modele\n",
    "start = time.time()\n",
    "grid_search_dtc.fit(data_train, label_train)\n",
    "end = time.time()\n",
    "print(\"Execution time for random search training: %f sec\"%(float(end) - float(start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "La meilleure combinaison d'hyperparametres avec grid search cv est :\n {'n_cuts': 55, 'max_depth': 35, 'max_features': 25}\n\nLe score moyen du modele avec ces hyperparametres est :\n 51.12\n"
    }
   ],
   "source": [
    "print(\"La meilleure combinaison d'hyperparametres avec grid search cv est :\\n\", grid_search_dtc.best_params_)\n",
    "print(\"\")\n",
    "print(\"Le score moyen du modele avec ces hyperparametres est :\\n %.2f\"%grid_search_dtc.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sauvegarde le meilleur modèle."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dtc = grid_search_dtc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de validation\n",
    "predictions = best_dtc.predict(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voyons si le réglage des hyper-paramètres a permis d'obtenir un meilleur modèle"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Base model score: 41.0 %\nBest model score: 51.0 %\n"
    }
   ],
   "source": [
    "print(\"Base model score: {} %\".format(base_model.score(our_predictions, label_test) * 100))\n",
    "print(\"Best model score: {} %\".format(best_dtc.score(predictions, label_test) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegardons le score du modèle pour pouvoir le comparer aux autres modèles."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    'Model': 'Decision Tree',\n",
    "    'Test Set Accuracy': best_dtc.score_\n",
    "}\n",
    "\n",
    "df_models_dtc = pd.DataFrame(d, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Models/best_dtc.pickle', 'wb') as output:\n",
    "    pickle.dump(best_dtc, output)\n",
    "\n",
    "with open('Models/df_models_dtc.pickle', 'wb') as output:\n",
    "    pickle.dump(df_models_dtc, output)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit130b65de45ae4ae8a1d5066beb0585a6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
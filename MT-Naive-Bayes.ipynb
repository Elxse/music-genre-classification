{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rd\n",
    "import time\n",
    "import pickle\n",
    "from collections import defaultdict \n",
    "\n",
    "# Scikit-learn modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Nos modules\n",
    "from modules.naivebayes import OurNaiveBayesClassifier as nb\n",
    "import modules.feature_selection as fs\n",
    "import modules.scoring as sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "featureNames = [e for e in data.columns]\n",
    "\n",
    "# On supprime la premiere colonne\n",
    "data = data.drop(['filename'],axis=1)\n",
    "\n",
    "#Test\n",
    "#data = data.drop(columns=['chroma_stft','rms','spectral_centroid','spectral_bandwidth','rolloff','zero_crossing_rate','spectral_flatness','tonnetz','estimated_tempo','spectral_contrast'])\n",
    "#data = data.drop(columns=['estimated_tempo'])\n",
    "\n",
    "# On change les noms des genres par des entiers (de 0 a 9) car notre random forest ne prend en compte que des entiers comme labels\n",
    "\n",
    "genre_list = data.iloc[:, -1]\n",
    "encoder = LabelEncoder()\n",
    "labels = encoder.fit_transform(genre_list)\n",
    "data.iloc[:, -1] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Apprentissage du modèle de base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sépare tout d'abord le jeu de données pour constituer un ensemble d'apprentissage et de validation. <br>\n",
    "Le Gaussian Naive Bayes ne prend pas d'hyper-paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On separe le dataset en train set et test set (80%/20%)\n",
    "data2 = data.copy()\n",
    "train_set = data2.sample(frac=0.80, random_state=rd.randint(0,100000))\n",
    "test_set = data2.drop(train_set.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nb.OurNaiveBayesClassifier()\n",
    "classifier = classifier.fit(train_set)\n",
    "\n",
    "new_test_set = test_set.copy()\n",
    "new_test_set = new_test_set.drop(columns=['genre/label'])\n",
    "\n",
    "predictions = classifier.predict(new_test_set)\n",
    "result = classifier.score(predictions, test_set['genre/label'].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis on compare la performance de notre Naive Bayes avec celle de scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On compare avec sklearn\n",
    "X = train_set.loc[:, train_set.columns != 'genre/label']\n",
    "y = train_set['genre/label']\n",
    "\n",
    "sk_new_test_set = test_set.copy()\n",
    "sk_new_test_set = sk_new_test_set.drop(columns=['genre/label'])\n",
    "\n",
    "sklearn_nb = GaussianNB()\n",
    "sklearn_nb.fit(X, y)\n",
    "sklearn_predictions = sklearn_nb.predict(sk_new_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Naive Bayes score : 45.5 %\n",
      "Sklearn score : 52.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Our Naive Bayes score : {} %\".format(result*100))\n",
    "print(\"Sklearn score : {} %\".format(classifier.score(sklearn_predictions, test_set['genre/label'].to_list())*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Wrapper-based Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_train (800, 30) | label_train (800,)\n",
      "data_test  (200, 30) | label_test  (200,)\n"
     ]
    }
   ],
   "source": [
    "# On normalise le dataset\n",
    "scaler = StandardScaler()\n",
    "data_normalized = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))\n",
    "\n",
    "# On separe le dataset en train set et test set (80%/20%)\n",
    "data_train, data_test, label_train, label_test = train_test_split(data_normalized, labels, test_size=0.2)\n",
    "n_samples, n_features = data_train.shape\n",
    "\n",
    "print(\"data_train {0} | label_train {1}\".format(data_train.shape, label_train.shape))\n",
    "print(\"data_test  {0} | label_test  {1}\".format(data_test.shape, label_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time to find the most important feature: 265.623772 sec\n"
     ]
    }
   ],
   "source": [
    "# 16 MIN\n",
    "start = time.time()\n",
    "features, importances = classifier.findFeatureImportance(train_set)\n",
    "end = time.time()\n",
    "print(\"Execution time to find the most important feature: %f sec\"%(float(end) - float(start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>spectral_flatness</td>\n",
       "      <td>0.11625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rms</td>\n",
       "      <td>0.08000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chroma_stft</td>\n",
       "      <td>0.06625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>zero_crossing_rate</td>\n",
       "      <td>0.04750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mfcc15</td>\n",
       "      <td>0.00375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mfcc12</td>\n",
       "      <td>0.00375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mfcc10</td>\n",
       "      <td>0.00375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mfcc11</td>\n",
       "      <td>0.00250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tonnetz</td>\n",
       "      <td>0.00250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>spectral_contrast</td>\n",
       "      <td>0.00250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               feature  importance\n",
       "27   spectral_flatness     0.11625\n",
       "1                  rms     0.08000\n",
       "0          chroma_stft     0.06625\n",
       "5   zero_crossing_rate     0.04750\n",
       "20              mfcc15     0.00375\n",
       "17              mfcc12     0.00375\n",
       "15              mfcc10     0.00375\n",
       "16              mfcc11     0.00250\n",
       "28             tonnetz     0.00250\n",
       "26   spectral_contrast     0.00250"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_name = data.drop(['genre/label'], axis=1).columns\n",
    "feature_importances = pd.DataFrame(zip(features_name, importances), columns = ['feature','importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "feature_importances[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On selectionne les caracteristiques dont l'importance est superieur a 0\n",
    "indexes = feature_importances[feature_importances['importance'] > 0.000125].index\n",
    "df_fs = train_set.iloc[indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On compare avec sklearn\n",
    "\n",
    "#X = df_fs.loc[:, train_set.columns != 'genre/label']\n",
    "X = df_fs.drop(columns=['genre/label'])\n",
    "y = df_fs['genre/label']\n",
    "\n",
    "test_set_fs = test_set.copy()\n",
    "test_set_fs = test_set_fs.drop(columns=['genre/label'])\n",
    "\n",
    "sklearn_nb = GaussianNB()\n",
    "sklearn_nb.fit(X, y)\n",
    "sklearn_predictions = sklearn_nb.predict(test_set_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn score after fs: 27.500000000000004 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Sklearn score after fs: {} %\".format(classifier.score(sklearn_predictions, test_set['genre/label'].to_list())*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que le score après la sélection des caractéristisques est nettement plus bas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

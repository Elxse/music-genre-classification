{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rd\n",
    "import time\n",
    "\n",
    "from collections import defaultdict \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Du precedent projet\n",
    "import randomforest as rf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importation des données"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1000, 32)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        filename  chroma_stft       rms  spectral_centroid  \\\n0  country.00094     0.366838  0.206715        1474.849928   \n1  country.00025     0.347253  0.079920        1565.431223   \n2  country.00076     0.297332  0.128385        1321.679067   \n3  country.00030     0.221390  0.079631        1240.515214   \n4  country.00089     0.322114  0.104638        1321.678546   \n\n   spectral_bandwidth      rolloff  zero_crossing_rate      mfcc1      mfcc2  \\\n0         1745.839794  3108.264538            0.062993 -104.34503  136.39078   \n1         2016.069774  3188.930717            0.057303 -200.55273  119.67490   \n2         1409.586676  2590.392670            0.066525 -183.93301  159.80644   \n3         1996.754074  2412.635411            0.042844 -277.08127  128.25803   \n4         1667.211777  2583.926042            0.052503 -205.12328  140.99438   \n\n       mfcc3  ...     mfcc16    mfcc17    mfcc18    mfcc19     mfcc20  \\\n0 -20.945368  ...   2.197093 -7.109390  1.849674  1.675598  -1.492039   \n1  -3.610737  ... -11.293138 -8.870809 -8.073557 -3.161044   0.330751   \n2 -23.158834  ...  -3.583324 -9.062474 -3.159365 -4.068544  -7.052489   \n3  42.433240  ...   1.391878  3.080010  2.513260 -1.051766  -2.753359   \n4  -8.959963  ...   3.140506 -4.527332  2.654261 -3.122376 -10.710899   \n\n   spectral_contrast  spectral_flatness   tonnetz  estimated_tempo  \\\n0          23.567712           0.001825  0.026578       112.347147   \n1          19.845071           0.008667  0.018447       143.554688   \n2          23.526738           0.001220 -0.013900       143.554688   \n3          22.093318           0.002381 -0.009946       161.499023   \n4          24.189410           0.001850  0.002900       143.554688   \n\n   genre/label  \n0      country  \n1      country  \n2      country  \n3      country  \n4      country  \n\n[5 rows x 32 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>chroma_stft</th>\n      <th>rms</th>\n      <th>spectral_centroid</th>\n      <th>spectral_bandwidth</th>\n      <th>rolloff</th>\n      <th>zero_crossing_rate</th>\n      <th>mfcc1</th>\n      <th>mfcc2</th>\n      <th>mfcc3</th>\n      <th>...</th>\n      <th>mfcc16</th>\n      <th>mfcc17</th>\n      <th>mfcc18</th>\n      <th>mfcc19</th>\n      <th>mfcc20</th>\n      <th>spectral_contrast</th>\n      <th>spectral_flatness</th>\n      <th>tonnetz</th>\n      <th>estimated_tempo</th>\n      <th>genre/label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>country.00094</td>\n      <td>0.366838</td>\n      <td>0.206715</td>\n      <td>1474.849928</td>\n      <td>1745.839794</td>\n      <td>3108.264538</td>\n      <td>0.062993</td>\n      <td>-104.34503</td>\n      <td>136.39078</td>\n      <td>-20.945368</td>\n      <td>...</td>\n      <td>2.197093</td>\n      <td>-7.109390</td>\n      <td>1.849674</td>\n      <td>1.675598</td>\n      <td>-1.492039</td>\n      <td>23.567712</td>\n      <td>0.001825</td>\n      <td>0.026578</td>\n      <td>112.347147</td>\n      <td>country</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>country.00025</td>\n      <td>0.347253</td>\n      <td>0.079920</td>\n      <td>1565.431223</td>\n      <td>2016.069774</td>\n      <td>3188.930717</td>\n      <td>0.057303</td>\n      <td>-200.55273</td>\n      <td>119.67490</td>\n      <td>-3.610737</td>\n      <td>...</td>\n      <td>-11.293138</td>\n      <td>-8.870809</td>\n      <td>-8.073557</td>\n      <td>-3.161044</td>\n      <td>0.330751</td>\n      <td>19.845071</td>\n      <td>0.008667</td>\n      <td>0.018447</td>\n      <td>143.554688</td>\n      <td>country</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>country.00076</td>\n      <td>0.297332</td>\n      <td>0.128385</td>\n      <td>1321.679067</td>\n      <td>1409.586676</td>\n      <td>2590.392670</td>\n      <td>0.066525</td>\n      <td>-183.93301</td>\n      <td>159.80644</td>\n      <td>-23.158834</td>\n      <td>...</td>\n      <td>-3.583324</td>\n      <td>-9.062474</td>\n      <td>-3.159365</td>\n      <td>-4.068544</td>\n      <td>-7.052489</td>\n      <td>23.526738</td>\n      <td>0.001220</td>\n      <td>-0.013900</td>\n      <td>143.554688</td>\n      <td>country</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>country.00030</td>\n      <td>0.221390</td>\n      <td>0.079631</td>\n      <td>1240.515214</td>\n      <td>1996.754074</td>\n      <td>2412.635411</td>\n      <td>0.042844</td>\n      <td>-277.08127</td>\n      <td>128.25803</td>\n      <td>42.433240</td>\n      <td>...</td>\n      <td>1.391878</td>\n      <td>3.080010</td>\n      <td>2.513260</td>\n      <td>-1.051766</td>\n      <td>-2.753359</td>\n      <td>22.093318</td>\n      <td>0.002381</td>\n      <td>-0.009946</td>\n      <td>161.499023</td>\n      <td>country</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>country.00089</td>\n      <td>0.322114</td>\n      <td>0.104638</td>\n      <td>1321.678546</td>\n      <td>1667.211777</td>\n      <td>2583.926042</td>\n      <td>0.052503</td>\n      <td>-205.12328</td>\n      <td>140.99438</td>\n      <td>-8.959963</td>\n      <td>...</td>\n      <td>3.140506</td>\n      <td>-4.527332</td>\n      <td>2.654261</td>\n      <td>-3.122376</td>\n      <td>-10.710899</td>\n      <td>24.189410</td>\n      <td>0.001850</td>\n      <td>0.002900</td>\n      <td>143.554688</td>\n      <td>country</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 32 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On supprime la premiere colonne\n",
    "data = data.drop(['filename'],axis=1)\n",
    "\n",
    "# On change les noms des genres par des entiers (de 0 a 9) car notre random forest ne prend en compte que des entiers comme labels\n",
    "genre_list = data.iloc[:, -1]\n",
    "encoder = LabelEncoder()\n",
    "labels = encoder.fit_transform(genre_list)\n",
    "data.iloc[:, -1] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On normalise le dataset\n",
    "scaler = StandardScaler()\n",
    "data_normalized = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Apprentissage du modèle de base\n",
    "On reprend le modèle que nous avions implementé lors du précédent projet."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "data_train (800, 30) | label_train (800,)\ndata_test  (200, 30) | label_test  (200,)\n"
    }
   ],
   "source": [
    "# On separe le dataset en train set et test set (80%/20%)\n",
    "data_train, data_test, label_train, label_test = train_test_split(data_normalized, labels, test_size=0.2)\n",
    "print(\"data_train {0} | label_train {1}\".format(data_train.shape, label_train.shape))\n",
    "print(\"data_test  {0} | label_test  {1}\".format(data_test.shape, label_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Execution time for building the forest: 22.868670 sec\n"
    }
   ],
   "source": [
    "# Initialisation de la random forest\n",
    "# par defaut n_trees = 200, n_samples = 100, n_cuts = 20, max_depth = 20\n",
    "rf_classifier = rf.OurRandomForestClassifier() \n",
    "\n",
    "# Entrainement du modèle de base\n",
    "start = time.time()\n",
    "rf_classifier.fit(data_train, label_train)\n",
    "end = time.time()\n",
    "print(\"Execution time for building the forest: %f sec\"%(float(end) - float(start)))\n",
    "\n",
    "# Test de validation\n",
    "our_predictions = [rf_classifier.predict(data_test[i,:]) for i in range(data_test.shape[0])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison avec sklearn\n",
    "sklearn_rf = RandomForestClassifier(n_estimators=100, max_depth=20, max_features='sqrt')\n",
    "sklearn_rf.fit(data_train, label_train)\n",
    "sklearn_predictions = sklearn_rf.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Our random forest score : 66.0 %\nSklearn score : 74.0 %\n"
    }
   ],
   "source": [
    "print(\"Our random forest score : {} %\".format(rf_classifier.score(our_predictions, label_test) * 100))  \n",
    "print(\"Sklearn score : {} %\".format(rf_classifier.score(sklearn_predictions, label_test)*100))          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a une très grande marge d'amélioration."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature selection\n",
    "Un moyen d'améliorer notre modèle est de sélectionner les caractéristiques les plus discriminantes. \n",
    "\n",
    "* https://towardsdatascience.com/de-coding-random-forests-82d4dcbb91a1\n",
    "* https://hub.packtpub.com/4-ways-implement-feature-selection-python-machine-learning/"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Shape of the dataset  (800, 30)\nSize of the dataset before feature selection: 0.19 MB\n"
    }
   ],
   "source": [
    "print(\"Shape of the dataset \", data_train.shape)\n",
    "print(\"Size of the dataset before feature selection: %.2f MB\"%(data_train.nbytes/1e6))\n",
    "features_name = data.drop(['genre/label'], axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Execution time to find the most important feature: 49.854136 sec\n"
    }
   ],
   "source": [
    "start = time.time()\n",
    "features, importances = rf_classifier.findFeatureImportance(data_train, label_train)\n",
    "end = time.time()\n",
    "print(\"Execution time to find the most important feature: %f sec\"%(float(end) - float(start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "              feature  importance\n26  spectral_contrast     0.04500\n0         chroma_stft     0.04000\n14              mfcc9     0.02125\n9               mfcc4     0.02125\n22             mfcc17     0.01375\n18             mfcc13     0.01250\n17             mfcc12     0.01125\n24             mfcc19     0.01125\n16             mfcc11     0.01125\n2   spectral_centroid     0.00875",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature</th>\n      <th>importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>26</th>\n      <td>spectral_contrast</td>\n      <td>0.04500</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>chroma_stft</td>\n      <td>0.04000</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>mfcc9</td>\n      <td>0.02125</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>mfcc4</td>\n      <td>0.02125</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>mfcc17</td>\n      <td>0.01375</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>mfcc13</td>\n      <td>0.01250</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>mfcc12</td>\n      <td>0.01125</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>mfcc19</td>\n      <td>0.01125</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>mfcc11</td>\n      <td>0.01125</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spectral_centroid</td>\n      <td>0.00875</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(zip(features_name, importances), columns = ['feature','importance']).sort_values('importance', ascending=False)\n",
    "\n",
    "feature_importances[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Shape of the dataset  (800, 25)\nSize of the dataset after feature selection: 0.16 MB\n"
    }
   ],
   "source": [
    "# On selectionne les 25 meilleures\n",
    "indexes = feature_importances.index[:25]\n",
    "\n",
    "# On transforme le dataset d'entrainement (fs = feature selection)\n",
    "fs_data_train = rf.transform(data_train, indexes)\n",
    "fs_data_test = rf.transform(data_test, indexes)\n",
    "print(\"Shape of the dataset \", fs_data_train.shape)\n",
    "print(\"Size of the dataset after feature selection: %.2f MB\"%(fs_data_train.nbytes/1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Execution time for building the forest: 16.504025 sec\n"
    }
   ],
   "source": [
    "# Entrainement du modèle de base avec feature selection\n",
    "start = time.time()\n",
    "rf_classifier.fit(fs_data_train, label_train)\n",
    "end = time.time()\n",
    "print(\"Execution time for building the forest: %f sec\"%(float(end) - float(start)))\n",
    "\n",
    "# Test de validation\n",
    "our_predictions = [rf_classifier.predict(fs_data_test[i,:]) for i in range(data_test.shape[0])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison avec sklearn\n",
    "sklearn_rf.fit(fs_data_train, label_train)\n",
    "sklearn_predictions = sklearn_rf.predict(fs_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Our random forest score after feature selection: 59.5 %\nSklearn score : 75.0 %\n"
    }
   ],
   "source": [
    "# Score\n",
    "print(\"Our random forest score after feature selection: {} %\".format(rf_classifier.score(our_predictions, label_test) * 100))\n",
    "print(\"Sklearn score : {} %\".format(rf_classifier.score(sklearn_predictions, label_test)*100))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Réglage des hyperparamètres\n",
    "Nous nous sommes fortement inspiré de la méthode décrite dans cet article [W. Koehrsen. Hyperparameter Tuning the Random Forest in Python, Janv. 2018](https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre modèle a cinq paramètres, dont quatre que nous souhaitons optimiser  :\n",
    "   - `n_trees` -- le nombre d'arbres de la forêt\n",
    "   - `n_samples` -- le nombre de données à placer dans le noeud de chaque arbre avant qu'il ne soit partitionné\n",
    "   - `n_cuts` -- le nombre de coupes à tester pour trouver la meilleure\n",
    "   - `max_depth` -- la profondeur maximale de chaque arbre"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour avoir une première idée de la meilleure combinaison d'hyperparamètres, nous allons effectuer une ... (Random Search Cross Validation). Cela consiste à tester un large choix de combinaisons qui ont été formées en tirant aléatoirement des valeurs dans une grille d'hyperparamètres."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Random Search Cross Validation"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Hyperparameter Grid"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit la grille pour la recherche aléatoire (Random Hyperparameter Grid) :"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_trees\n",
    "n_trees = [int(x) for x in np.linspace(start = 200, stop = 800, num = 10)] \n",
    "\n",
    "# n_samples\n",
    "n_samples = [int(x) for x in np.linspace(start = 200, stop = 700, num = 10)]\n",
    "\n",
    "# n_cuts \n",
    "# dans quel intervalle pourrait on tester ??\n",
    "n_cuts = [int(x) for x in np.linspace(start = 10, stop = 100, num = 5)] \n",
    "\n",
    "# max_depth\n",
    "max_depth = [int(x) for x in np.linspace(10, 100, num = 10)]\n",
    "# Est-ce qu'on ajoute un None comme dans l'article ? A voir selon notre random forest, est-ce qu'elle prend en compte\n",
    "# un arg None pour max_depth ?\n",
    "\n",
    "# Creation de la grille\n",
    "random_grid = {'n_trees': n_trees,\n",
    "                'n_samples': n_samples,\n",
    "                'n_cuts': n_cuts,\n",
    "                'max_depth': max_depth}\n",
    "\n",
    "from pprint import pprint\n",
    "print(\"Grille d'hyperparametres :\\n\")\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au lieu de tester 10 * 10 * 5 * 10 = 5000 combinaisons d'hyperparamètres, nous allons seulement en sélectionner quelques unes aléatoirement."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Search Training"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On construit tout d'abord le modèle de base."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On separe le dataset en train set et test set (80%/20%)\n",
    "data_train, data_test, label_train, label_test = train_test_split(data, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_rf = rf.OurRandomForestClassifier() # choix aléatoire\n",
    "our_rf.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On procède à la recherche randomisée sur 50 combinaisons, en utilisant une 3-fold CV"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NE PAS RUN (CA PREND PLUS D'1/4  D'HEURE)\n",
    "# Definition de la recherche randomisee\n",
    "rf_random = RandomizedSearchCV(estimator = our_rf, \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 5, \n",
    "                               cv = 3, \n",
    "                               verbose = 2, \n",
    "                               random_state = 8)\n",
    "# je dois encore comprendre les differents parametres\n",
    "\n",
    "# Entrainement du modele\n",
    "rf_random.fit(data_train, label_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les resultats"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"La meilleure combinaison d'hyperparametres avec la recherche randomisee est :\")\n",
    "print(rf_random.best_params_)\n",
    "print(\"\")\n",
    "print(\"Le score moyen du modele avec ces hyperparametres est :\")\n",
    "print(rf_random.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Grid Search Cross Validation\n",
    "Une fois qu'on connait a peu pres les meilleurs hyper-parametres\n",
    "Plus d'aleatoire, on teste toutes les combinaisons"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit130b65de45ae4ae8a1d5066beb0585a6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}